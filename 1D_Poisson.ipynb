{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27af5100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (for Google Colab)\n",
    "!pip install pyDOE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffe868c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax, flax, optax, time, pickle\n",
    "import os\n",
    "import jax.numpy as np\n",
    "import numpy as onp\n",
    "from functools import partial\n",
    "from pyDOE import lhs\n",
    "from typing import Sequence\n",
    "import json\n",
    "from tensorflow_probability.substrates import jax as tfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5543116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run on the first GPU\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "from jax.extend.backend import get_backend\n",
    "print(get_backend().platform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90993946",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d466d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture_list = [[1, 1], [2, 1], [5, 1], [10, 1], [20, 1], [40, 1],\n",
    "                     [5, 5, 1], [10, 10, 1], [20, 20, 1], [40, 40, 1],\n",
    "                     [5, 5, 5, 1], [10, 10, 10, 1], [20, 20, 20, 1],\n",
    "                     [40, 40, 40, 1]] # NN architecture list\n",
    "lr = 1e-4 # learning rate\n",
    "num_epochs = 15000 # number of training epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af130ab8",
   "metadata": {},
   "source": [
    "# NN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0732bf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define NN architecture\n",
    "class PDESolution(flax.linen.Module): # inherit from Module class\n",
    "    features: Sequence[int] # dataclass (e.g. [10, 20, 1])\n",
    "\n",
    "    @flax.linen.compact # a decorator to define the model in more concise and readable way\n",
    "    def __call__(self, x): # __call__: makes an object callable, which enables you to use instances of the class like functions\n",
    "        for feature in features[:-1]:\n",
    "            x = flax.linen.tanh(flax.linen.Dense(feature)(x))\n",
    "        # Final Dense layer\n",
    "        x = flax.linen.Dense(features[-1])(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00e3586",
   "metadata": {},
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7622f7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hessian-vector product\n",
    "# (it is more general approach than gradient, even if it doesn't make a change in this 1D problem)\n",
    "def hvp(f, primals, tangents):\n",
    "    return jax.jvp(jax.grad(lambda x: f(x)[0]), primals, tangents)[1]\n",
    "\n",
    "# PDE residual\n",
    "@partial(jax.vmap, in_axes = (None, 0), out_axes = 0)\n",
    "@partial(jax.jit, static_argnums = (0,)) # decorator closest to the function is applied first\n",
    "def residual(u, x):\n",
    "    v = np.ones(x.shape)\n",
    "    lhs = hvp(u, (x,), (v,))\n",
    "    rhs = (-6*x + 4*x**3) * np.exp(-x ** 2)\n",
    "    return lhs - rhs\n",
    "\n",
    "# Loss functionals\n",
    "@jax.jit\n",
    "def pde_residual(params, points):\n",
    "    return np.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax-fem-pinns",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
